name: Ephemeral Sandbox Execution

on:
  workflow_dispatch:
    inputs:
      llm_prompt:
        description: 'LLM analysis prompt'
        required: true
        type: string
      dataset_secret:
        description: 'Name of GitHub secret containing dataset'
        required: true
        type: choice
        options:
          - PRIVATE_DATASET
          - SAMPLE_DATASET
        default: 'PRIVATE_DATASET'
      model:
        description: 'LLM model to use'
        required: false
        type: string
        default: 'claude-sonnet-4'
      tools:
        description: 'Tools to use (comma-separated: python,bash,grep)'
        required: false
        type: string
        default: 'python,bash'

jobs:
  execute:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install anthropic
      
      - name: Generate execution metadata
        id: metadata
        env:
          MODEL: ${{ github.event.inputs.model }}
          TOOLS: ${{ github.event.inputs.tools }}
        run: |
          echo "execution_id=$(uuidgen)" >> $GITHUB_OUTPUT
          echo "timestamp=$(date -Iseconds)" >> $GITHUB_OUTPUT
          echo "üé¨ Starting ephemeral execution..."
          echo "   Execution ID: $(uuidgen)"
          echo "   Timestamp: $(date -Iseconds)"
          echo "   Model: $MODEL"
          echo "   Tools: $TOOLS"
      
      - name: Load and hash dataset
        id: dataset
        env:
          DATASET: ${{ secrets[github.event.inputs.dataset_secret] }}
          DATASET_SECRET_NAME: ${{ github.event.inputs.dataset_secret }}
        run: |
          # Validate dataset exists
          if [ -z "$DATASET" ]; then
            echo "‚ùå Error: Dataset secret '$DATASET_SECRET_NAME' is empty or not found"
            exit 1
          fi
          
          # Generate hash (without logging dataset)
          HASH=$(echo -n "$DATASET" | sha256sum | cut -d' ' -f1)
          SIZE=$(echo -n "$DATASET" | wc -c)
          
          echo "dataset_hash=$HASH" >> $GITHUB_OUTPUT
          echo "dataset_size=$SIZE" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Dataset loaded successfully"
          echo "   Hash: ${HASH:0:16}...${HASH: -16}"
          echo "   Size: $SIZE bytes"
          echo "   ‚ö†Ô∏è  Dataset is in memory (not logged, not on disk)"
      
      - name: Execute LLM analysis
        id: execute
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          DATASET: ${{ secrets[github.event.inputs.dataset_secret] }}
          PROMPT: ${{ github.event.inputs.llm_prompt }}
          MODEL: ${{ github.event.inputs.model }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import anthropic
          import json
          import time
          
          start_time = time.time()
          
          # Get inputs (dataset from environment, not logged)
          dataset = os.environ['DATASET']
          prompt = os.environ['PROMPT']
          model = os.environ['MODEL']
          
          print(f"ü§ñ Executing LLM analysis...")
          print(f"   Model: {model}")
          print(f"   Prompt: {prompt[:100]}{'...' if len(prompt) > 100 else ''}")
          print(f"   Dataset size: {len(dataset)} chars")
          print()
          
          # Run LLM
          client = anthropic.Anthropic(api_key=os.environ['ANTHROPIC_API_KEY'])
          
          full_prompt = f"""{prompt}

<dataset>
{dataset}
</dataset>

Analyze the dataset above according to the prompt. Be specific and provide evidence from the data.
IMPORTANT: Do NOT reproduce raw dataset records in your response. Provide only aggregate statistics, counts, and thematic summaries."""
          
          response = client.messages.create(
              model=model,
              max_tokens=4096,
              messages=[{
                  "role": "user",
                  "content": full_prompt
              }]
          )
          
          result = response.content[0].text
          tokens_in = response.usage.input_tokens
          tokens_out = response.usage.output_tokens
          tokens_total = tokens_in + tokens_out
          
          elapsed = time.time() - start_time
          
          print(f"‚úÖ Analysis complete!")
          print(f"   Duration: {elapsed:.2f}s")
          print(f"   Tokens: {tokens_total} ({tokens_in} in, {tokens_out} out)")
          print()
          print("=" * 60)
          print("üìä RESULT:")
          print("=" * 60)
          # Redaction gate: reject output that looks like it contains raw dataset records
          import re as _re
          # Check for common data leak patterns: emails, credit cards, SSNs, phone numbers
          leak_patterns = [
              _re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'),  # email
              _re.compile(r'\b\d{3}[-.]?\d{2}[-.]?\d{4}\b'),  # SSN-like
              _re.compile(r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b'),  # credit card-like
          ]
          leak_count = sum(len(pat.findall(result)) for pat in leak_patterns)
          if leak_count > 5:
              print("[REDACTED ‚Äî output contained potential raw dataset records]")
              print(f"   ({leak_count} PII-like patterns detected. Review artifacts directly.)")
          else:
              print(result)
          print("=" * 60)
          print()
          
          # Save result to file
          with open('result.txt', 'w') as f:
              f.write(result)
          
          # Save execution trace
          trace = {
              "execution_time_seconds": elapsed,
              "tokens": {
                  "input": tokens_in,
                  "output": tokens_out,
                  "total": tokens_total
              },
              "model": model,
              "prompt_length": len(prompt),
              "dataset_size": len(dataset)
          }
          
          with open('execution_trace.json', 'w') as f:
              json.dump(trace, f, indent=2)
          
          print("üóëÔ∏è  Dataset will be deleted when this runner is destroyed")
          PYTHON_SCRIPT
      
      - name: Generate execution certificate
        id: certificate
        env:
          INPUT_DATASET_SECRET: ${{ github.event.inputs.dataset_secret }}
          INPUT_MODEL: ${{ github.event.inputs.model }}
          INPUT_TOOLS: ${{ github.event.inputs.tools }}
          INPUT_PROMPT: ${{ github.event.inputs.llm_prompt }}
          META_TIMESTAMP: ${{ steps.metadata.outputs.timestamp }}
          DS_HASH: ${{ steps.dataset.outputs.dataset_hash }}
          DS_SIZE: ${{ steps.dataset.outputs.dataset_size }}
          RUN_ID: ${{ github.run_id }}
          RUN_NUMBER: ${{ github.run_number }}
          REPO: ${{ github.repository }}
        run: |
          # Read execution trace
          TRACE=$(cat execution_trace.json)
          DURATION=$(echo "$TRACE" | jq -r '.execution_time_seconds')
          TOKENS=$(echo "$TRACE" | jq -r '.tokens.total')
          RESULT=$(cat result.txt)

          # Generate certificate in step summary using env vars (not expression interpolation)
          cat >> $GITHUB_STEP_SUMMARY <<CERT_EOF
          # üìú Execution Certificate

          ## Execution Metadata

          | Field | Value |
          |-------|-------|
          | **Certificate ID** | \`${RUN_ID}-${RUN_NUMBER}\` |
          | **Timestamp** | \`${META_TIMESTAMP}\` |
          | **Status** | ‚úÖ Success |
          | **Duration** | \`${DURATION}\` seconds |

          ## Dataset

          | Field | Value |
          |-------|-------|
          | **Hash** | \`${DS_HASH}\` |
          | **Size** | \`${DS_SIZE}\` bytes |
          | **Source** | Secret: \`${INPUT_DATASET_SECRET}\` |
          | **Status** | ‚ö†Ô∏è  **NEVER STORED** (ephemeral, deleted after execution) |

          ## Sandbox Specification

          | Field | Value |
          |-------|-------|
          | **LLM Model** | \`${INPUT_MODEL}\` |
          | **Tools** | \`${INPUT_TOOLS}\` |
          | **Tokens Used** | \`${TOKENS}\` |

          ### Prompt
          \`\`\`
          ${INPUT_PROMPT}
          \`\`\`

          ## Result

          \`\`\`
          ${RESULT}
          \`\`\`

          ## Execution Trace

          \`\`\`json
          ${TRACE}
          \`\`\`

          ## Verification

          ‚úÖ **Certificate URL:** https://github.com/${REPO}/actions/runs/${RUN_ID}

          Anyone can verify:
          - ‚úÖ Execution happened at specified time
          - ‚úÖ Used specified prompt and model
          - ‚úÖ Dataset hash matches expected value
          - ‚úÖ Result is authentic (tamper-proof logs)
          - ‚ùå Private dataset NOT accessible (deleted)

          ## Lifecycle

          | Event | Status |
          |-------|--------|
          | Dataset loaded | ‚úÖ Complete |
          | LLM execution | ‚úÖ Complete |
          | Result generated | ‚úÖ Complete |
          | Dataset deleted | ‚úÖ Complete (runner destroyed) |
          | Certificate issued | ‚úÖ Complete |

          ---

          **ü¶û Ephemeral Sandbox Execution**
          Private data ¬∑ Public proof ¬∑ Zero retention

          CERT_EOF

          # Print certificate URL
          echo "üìú Certificate URL:"
          echo "   https://github.com/${REPO}/actions/runs/${RUN_ID}"
          
      - name: Upload execution artifacts
        uses: actions/upload-artifact@v4
        with:
          name: execution-certificate-${{ github.run_id }}
          path: |
            result.txt
            execution_trace.json
          retention-days: 90
      
      - name: Cleanup confirmation
        env:
          REPO: ${{ github.repository }}
          RUN_ID: ${{ github.run_id }}
        run: |
          echo "üóëÔ∏è  Runner cleanup initiated..."
          echo "   Dataset: Will be deleted (runner destroyed)"
          echo "   Secrets: Remain in GitHub (not exposed)"
          echo "   Logs: Permanent (public, verifiable)"
          echo "   Artifacts: Retained for 90 days"
          echo ""
          echo "‚úÖ Ephemeral execution complete!"
          echo "   Certificate: https://github.com/${REPO}/actions/runs/${RUN_ID}"
